# ğŸš€ Backend AlugAI - Machine Learning API

Backend de Machine Learning para o sistema AlugAI, responsÃ¡vel pelo treinamento e serviÃ§o do modelo de prediÃ§Ã£o de preÃ§os de aluguel de imÃ³veis no Distrito Federal.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Treinamento do Modelo](#treinamento-do-modelo)
- [API REST](#api-rest)
- [Processamento de Dados](#processamento-de-dados)
- [Modelo de Machine Learning](#modelo-de-machine-learning)
- [Deploy](#deploy)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O backend AlugAI Ã© composto por:

- **Pipeline de Processamento de Dados**: Limpeza, feature engineering e preparaÃ§Ã£o dos dados
- **Modelo XGBoost**: Algoritmo de regressÃ£o para prediÃ§Ã£o de preÃ§os
- **API REST Flask**: ServiÃ§o web para servir prediÃ§Ãµes em tempo real
- **Endpoints de Dados**: Fornece dados Ãºnicos (cidades, bairros, tipos) para o frontend

---

## ğŸ“ Estrutura do Projeto

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py    # Processamento e feature engineering
â”‚   â””â”€â”€ model_trainer.py      # Treinamento e avaliaÃ§Ã£o do modelo
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ app.py                # API REST (Flask)
â”‚   â”œâ”€â”€ Procfile              # ConfiguraÃ§Ã£o para deploy (Render)
â”‚   â””â”€â”€ start_api.sh          # Script de inicializaÃ§Ã£o
â”œâ”€â”€ models/                   # Modelos treinados (gerado automaticamente)
â”‚   â”œâ”€â”€ model_*.pkl          # Modelo XGBoost
â”‚   â”œâ”€â”€ scaler_*.pkl         # Scaler para normalizaÃ§Ã£o
â”‚   â”œâ”€â”€ metadata_*.json       # Metadados do modelo
â”‚   â””â”€â”€ encoding_*.json       # Mapeamentos de encoding
â”œâ”€â”€ train_model.py           # Script principal de treinamento
â”œâ”€â”€ test_api.py              # Testes da API
â”œâ”€â”€ test_training.py         # Testes do pipeline de treinamento
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ render.yaml              # ConfiguraÃ§Ã£o para deploy no Render
â”œâ”€â”€ start.sh                 # Script alternativo de start
â””â”€â”€ README.md               # Este arquivo
```

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### Passo a Passo

1. **Navegue atÃ© o diretÃ³rio do backend:**
   ```bash
   cd backend
   ```

2. **Crie um ambiente virtual (recomendado):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # ou
   venv\Scripts\activate  # Windows
   ```

3. **Instale as dependÃªncias:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Para macOS (se necessÃ¡rio):**
   ```bash
   # XGBoost pode precisar de libomp
   brew install libomp
   ```

---

## ğŸ“Š Treinamento do Modelo

### Dataset

O modelo Ã© treinado com o dataset `data/imoveis-df.csv`, que contÃ©m informaÃ§Ãµes sobre imÃ³veis para aluguel no Distrito Federal.

### Executar Treinamento

```bash
cd backend
python train_model.py
```

### O que o script faz:

1. **Carrega os dados** de `../data/imoveis-df.csv`
2. **Processa os dados**:
   - Filtra apenas imÃ³veis para aluguel
   - Remove outliers (mÃ©todo IQR)
   - Trata valores faltantes
   - Aplica feature engineering
   - Faz encoding categÃ³rico
3. **Treina o modelo XGBoost**:
   - DivisÃ£o: 70% treino, 15% validaÃ§Ã£o, 15% teste
   - Cross-validation para avaliaÃ§Ã£o
4. **Avalia o modelo**:
   - MAE (Mean Absolute Error)
   - RMSE (Root Mean Squared Error)
   - RÂ² (Coeficiente de DeterminaÃ§Ã£o)
5. **Salva o modelo** em `models/`:
   - Modelo treinado (`.pkl`)
   - Scaler (`.pkl`)
   - Metadados (`.json`)
   - Mapeamentos de encoding (`.json`)

### SaÃ­da Esperada

```
INFO: Carregando dados...
INFO: Processando dados...
INFO: Treinando modelo...
INFO: Avaliando modelo...
INFO: MAE: 250.50
INFO: RMSE: 350.75
INFO: RÂ²: 0.85
INFO: Modelo salvo em models/model_20251209_194317.pkl
```

---

## ğŸ”Œ API REST

### Iniciar a API

```bash
cd backend/api
python app.py
```

A API estarÃ¡ disponÃ­vel em `http://localhost:5020`

### VariÃ¡veis de Ambiente

A API suporta as seguintes variÃ¡veis de ambiente:

- `PORT`: Porta do servidor (padrÃ£o: 5020)
- `DEBUG`: Modo debug (padrÃ£o: false)

### Endpoints DisponÃ­veis

#### `GET /health`

Health check da API e status do modelo.

**Resposta:**
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

#### `POST /predict`

PrediÃ§Ã£o de preÃ§o de aluguel.

**Body (JSON):**
```json
{
  "area": 70.0,
  "bedrooms": 2,
  "bathrooms": 2,
  "parking_spaces": 1,
  "furnished": false,
  "hoa": 400.0,
  "property_type": "Apartamento",
  "city": "BrasÃ­lia",
  "neighborhood": "asa norte",
  "suites": 0
}
```

**Resposta:**
```json
{
  "predicted_price": 2500.50,
  "price_per_sqm": 35.72,
  "model_version": "20251209_194317",
  "model_metrics": {
    "mae": 250.0,
    "rmse": 350.0,
    "r2": 0.85
  }
}
```

#### `GET /data/unique-values`

Retorna valores Ãºnicos de cidades, bairros e tipos de imÃ³veis.

**Resposta:**
```json
{
  "cities": ["BrasÃ­lia"],
  "neighborhoods": ["asa norte", "asa sul", "aguas claras", ...],
  "property_types": ["Apartamento", "Kitnet", "Casa", ...]
}
```

#### `GET /data/properties`

Retorna todos os imÃ³veis do dataset com filtros opcionais.

**Query Parameters:**
- `property_type`: Filtrar por tipo de imÃ³vel
- `neighborhood`: Filtrar por bairro
- `min_area`, `max_area`: Filtrar por Ã¡rea
- `min_bedrooms`, `max_bedrooms`: Filtrar por nÃºmero de quartos
- `min_price`, `max_price`: Filtrar por preÃ§o
- `limit`: Limite de resultados (padrÃ£o: 1000)
- `offset`: Offset para paginaÃ§Ã£o (padrÃ£o: 0)

**Exemplo:**
```
GET /data/properties?property_type=Apartamento&min_area=50&limit=10
```

**Resposta:**
```json
{
  "properties": [
    {
      "id": 0,
      "property_type": "Apartamento",
      "neighborhood": "asa norte",
      "area": 70.0,
      "bedrooms": 2,
      "bathrooms": 2,
      "parking_spaces": 1,
      "hoa": 400.0,
      "furnished": false,
      "rent_amount": 2500.0,
      "city": "BrasÃ­lia"
    }
  ],
  "total": 2858,
  "returned": 10,
  "offset": 0,
  "limit": 10
}
```

#### `GET /data/cities`

Lista de cidades disponÃ­veis.

#### `GET /data/neighborhoods`

Lista de bairros disponÃ­veis.

#### `GET /data/property-types`

Lista de tipos de imÃ³veis disponÃ­veis.

---

## ğŸ”§ Processamento de Dados

### Pipeline Completo

1. **Carregamento**: Leitura do CSV com separador `;`
2. **Filtragem**: Apenas imÃ³veis para aluguel
3. **SeleÃ§Ã£o de Features**:
   - NumÃ©ricas: `area`, `bedrooms`, `bathrooms`, `parking_spaces`, `hoa`, `suites`
   - CategÃ³ricas: `property_type`, `city`, `neighborhood`, `furnished`
4. **Tratamento de Missing Values**:
   - NumÃ©ricos: Mediana
   - CategÃ³ricos: 'Desconhecido'
5. **RemoÃ§Ã£o de Outliers**: MÃ©todo IQR (Interquartile Range)
6. **Feature Engineering**:
   - `price_per_sqm`: PreÃ§o por metro quadrado
7. **Encoding**:
   - One-Hot Encoding para `property_type` e `furnished`
   - Target Encoding para `city` e `neighborhood`
8. **NormalizaÃ§Ã£o**: StandardScaler para features numÃ©ricas

### Features Utilizadas

| Feature | Tipo | DescriÃ§Ã£o |
|---------|------|-----------|
| `area` | NumÃ©rica | Ãrea do imÃ³vel em mÂ² |
| `bedrooms` | NumÃ©rica | NÃºmero de quartos |
| `bathrooms` | NumÃ©rica | NÃºmero de banheiros |
| `parking_spaces` | NumÃ©rica | NÃºmero de vagas de garagem |
| `hoa` | NumÃ©rica | Valor do condomÃ­nio |
| `suites` | NumÃ©rica | NÃºmero de suÃ­tes |
| `furnished` | Booleana | ImÃ³vel mobiliado |
| `property_type` | CategÃ³rica | Tipo do imÃ³vel (Apartamento, Casa, etc.) |
| `city` | CategÃ³rica | Cidade (BrasÃ­lia) |
| `neighborhood` | CategÃ³rica | Bairro |
| `price_per_sqm` | NumÃ©rica (derivada) | PreÃ§o por metro quadrado |

---

## ğŸ¤– Modelo de Machine Learning

### Algoritmo

- **XGBoost Regressor**: Gradient Boosting para regressÃ£o
- **Target**: `rent_amount` (preÃ§o de aluguel em R$)

### HiperparÃ¢metros

```python
{
    'n_estimators': 100,
    'max_depth': 6,
    'learning_rate': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'random_state': 42
}
```

### MÃ©tricas de AvaliaÃ§Ã£o

- **MAE (Mean Absolute Error)**: Erro mÃ©dio absoluto em R$
- **RMSE (Root Mean Squared Error)**: Raiz do erro quadrÃ¡tico mÃ©dio
- **RÂ² (Coeficiente de DeterminaÃ§Ã£o)**: ProporÃ§Ã£o da variÃ¢ncia explicada (0-1)

### ValidaÃ§Ã£o

- DivisÃ£o: 70% treino, 15% validaÃ§Ã£o, 15% teste
- Cross-validation: 5 folds
- Early stopping: Baseado no conjunto de validaÃ§Ã£o

---

## ğŸš€ Deploy

### Render (Recomendado)

1. **Criar conta:** https://render.com
2. **Conectar repositÃ³rio GitHub**
3. **Configurar:**
   - **Name**: `alugai-api`
   - **Environment**: `Python 3`
   - **Root Directory**: `backend`
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `python api/app.py`
   - **Plan**: Free

4. **VariÃ¡veis de Ambiente:**
   - `PORT`: SerÃ¡ definido automaticamente pelo Render
   - `DEBUG`: `false`

5. **Upload dos Modelos:**
   - Commit os arquivos em `backend/models/` no GitHub
   - Ou use storage externo (S3, etc.)

### Verificar Deploy

```bash
curl https://seu-backend.onrender.com/health
```

---

## ğŸ§ª Testes

### Testar API Localmente

```bash
cd backend
python test_api.py
```

### Testar Pipeline de Treinamento

```bash
cd backend
python test_training.py
```

---

## ğŸ” Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'xgboost'"

**SoluÃ§Ã£o:**
```bash
pip install xgboost
```

### Erro: "XGBoost Library (libxgboost.dylib) could not be loaded" (macOS)

**SoluÃ§Ã£o:**
```bash
brew install libomp
```

### Erro: "Model not found"

**SoluÃ§Ã£o:**
1. Execute `python train_model.py` para gerar o modelo
2. Verifique se os arquivos estÃ£o em `backend/models/`

### Erro: "Port already in use"

**SoluÃ§Ã£o:**
1. Altere a porta no cÃ³digo ou variÃ¡vel de ambiente
2. Ou mate o processo usando a porta:
   ```bash
   lsof -ti:5020 | xargs kill -9
   ```

### API nÃ£o conecta ao modelo

**SoluÃ§Ã£o:**
1. Verifique os logs: `tail -f /tmp/api.log`
2. Confirme que o modelo estÃ¡ em `backend/models/`
3. Verifique se o caminho estÃ¡ correto no cÃ³digo

### Erro de encoding no dataset

**SoluÃ§Ã£o:**
1. Verifique se o CSV estÃ¡ em UTF-8
2. Confirme que o separador Ã© `;`
3. Verifique se as colunas estÃ£o corretas

---

## ğŸ“š DependÃªncias

- `pandas>=2.0.0`: ManipulaÃ§Ã£o de dados
- `numpy>=1.24.0`: OperaÃ§Ãµes numÃ©ricas
- `scikit-learn>=1.3.0`: Machine Learning
- `xgboost>=2.0.0`: Algoritmo XGBoost
- `flask>=2.3.0`: Framework web
- `flask-cors>=4.0.0`: CORS para integraÃ§Ã£o
- `requests>=2.31.0`: Cliente HTTP

---

## ğŸ”— IntegraÃ§Ã£o com Frontend

O frontend Streamlit consome a API atravÃ©s de requisiÃ§Ãµes HTTP:

```python
import requests

API_URL = "http://localhost:5020"  # ou URL do deploy

# PrediÃ§Ã£o
response = requests.post(f"{API_URL}/predict", json={
    'area': 70,
    'bedrooms': 2,
    'bathrooms': 2,
    'parking_spaces': 1,
    'furnished': False,
    'hoa': 400,
    'property_type': 'Apartamento',
    'city': 'BrasÃ­lia',
    'neighborhood': 'asa norte',
    'suites': 0
})

prediction = response.json()['predicted_price']
```

---

## ğŸ“ Notas Importantes

- O modelo Ã© treinado com dados do dataset completo
- Para produÃ§Ã£o, recomenda-se retreinar periodicamente
- Os modelos sÃ£o versionados por timestamp
- A API carrega automaticamente o modelo mais recente
- CORS estÃ¡ configurado para permitir requisiÃ§Ãµes do Streamlit Cloud

---

## ğŸ‘¥ Desenvolvido por

Equipe AlugAI - UnB 2025

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© de uso acadÃªmico e educacional.
